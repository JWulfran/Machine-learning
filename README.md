# ğŸŒ³ Classification avec Arbre de DÃ©cision - Python

Ce projet prÃ©sente une application pratique des **arbres de dÃ©cision** pour rÃ©soudre un problÃ¨me de classification supervisÃ©e. Il permet de visualiser les dÃ©cisions prises par lâ€™algorithme Ã  travers un graphe arborescent et dâ€™analyser les performances du modÃ¨le.

ğŸ”— **Notebook GitHub** : [Classification_tree.ipynb](https://github.com/JWulfran/Machine-learning/blob/115f7806111e91004a1b0b3f92fd9771cf98c8bc/Classification_tree.ipynb)

---

## ğŸ¯ Objectifs

- Comprendre le fonctionnement des **arbres de dÃ©cision**
- ImplÃ©menter un modÃ¨le de classification sur un jeu de donnÃ©es
- Visualiser la structure de lâ€™arbre
- Ã‰valuer les performances du modÃ¨le avec des mÃ©triques classiques

---

## ğŸ§° Technologies utilisÃ©es

- **Python**
  - `pandas`, `numpy` pour la manipulation des donnÃ©es
  - `scikit-learn` pour la modÃ©lisation (DecisionTreeClassifier)
  - `matplotlib`, `seaborn` pour la visualisation
  - `graphviz` ou `plot_tree` pour lâ€™arbre

---

## ğŸ§ª Ã‰tapes du projet

1. **Chargement et prÃ©paration des donnÃ©es**
   - Nettoyage, encodage des variables
2. **Construction du modÃ¨le**
   - Utilisation de `DecisionTreeClassifier` de scikit-learn
   - SÃ©paration entraÃ®nement/test
3. **Visualisation**
   - Affichage graphique de lâ€™arbre de dÃ©cision
   - Analyse des nÅ“uds et des critÃ¨res de dÃ©coupe
4. **Ã‰valuation**
   - Accuracy, matrice de confusion, classification report

---

## ğŸ“Š RÃ©sultats

- Le modÃ¨le est **interprÃ©table et visuel**, ce qui en fait un bon outil pour lâ€™explication mÃ©tier.
- Les performances varient selon les paramÃ¨tres comme la profondeur maximale.
- Permet dâ€™identifier rapidement les **variables les plus discriminantes**.

---

## ğŸ§  Ce que jâ€™ai appris

- Utiliser les arbres de dÃ©cision pour classer des donnÃ©es tabulaires
- Visualiser et interprÃ©ter les rÃ¨gles de classification
- Comparer les performances selon les rÃ©glages de lâ€™arbre
- Valoriser la simplicitÃ© et lâ€™interprÃ©tabilitÃ© des modÃ¨les ML

---

ğŸ“‚ _Ce projet sâ€™inscrit dans ma dÃ©marche dâ€™apprentissage du machine learning et de la visualisation explicative des modÃ¨les supervisÃ©s._

---

# ğŸ‘Ÿ Classification avec k-Nearest Neighbors (KNN) - Python

Ce projet met en Å“uvre lâ€™algorithme **KNN (k plus proches voisins)** pour rÃ©soudre un problÃ¨me de **classification supervisÃ©e**. Il explore lâ€™effet du paramÃ¨tre `k` sur les performances du modÃ¨le, ainsi que la visualisation des frontiÃ¨res de dÃ©cision.

ğŸ”— **Notebook GitHub** : [KNN.ipynb](https://github.com/JWulfran/Machine-learning/blob/115f7806111e91004a1b0b3f92fd9771cf98c8bc/KNN.ipynb)

---

## ğŸ¯ Objectifs

- ImplÃ©menter et comprendre lâ€™algorithme **KNN**
- Ã‰tudier lâ€™impact du nombre de voisins (`k`) sur la performance
- Visualiser les **zones de classification**
- Comparer les rÃ©sultats avec dâ€™autres algorithmes

---

## ğŸ§° Technologies utilisÃ©es

- **Python**
  - `pandas`, `numpy` pour la manipulation des donnÃ©es
  - `scikit-learn` pour lâ€™algorithme KNN et les mÃ©triques
  - `matplotlib`, `seaborn` pour les visualisations

---

## ğŸ§ª Ã‰tapes du projet

1. **Chargement et prÃ©paration des donnÃ©es**

   - Normalisation ou standardisation (important pour KNN)
   - SÃ©paration en jeu dâ€™entraÃ®nement/test

2. **EntraÃ®nement du modÃ¨le**

   - Utilisation de `KNeighborsClassifier` (Scikit-learn)
   - SÃ©lection du meilleur `k` via validation croisÃ©e ou test empirique

3. **Ã‰valuation**
   - Matrice de confusion
   - Score dâ€™exactitude (`accuracy`)
   - Visualisation des frontiÃ¨res de dÃ©cision

---

## ğŸ“Š RÃ©sultats

- Les performances varient fortement en fonction de la **valeur de `k`**.
- Visualisations trÃ¨s intuitives pour **comprendre la structure des donnÃ©es**.
- Le KNN est **sensible aux dimensions**, ce qui le rend plus adaptÃ© aux petits jeux de donnÃ©es.

---

## ğŸ§  Ce que jâ€™ai appris

- Appliquer et interprÃ©ter un modÃ¨le de classification KNN
- Importance de la mise Ã  lâ€™Ã©chelle des donnÃ©es pour les algorithmes basÃ©s sur la distance
- Utiliser les visualisations pour analyser les erreurs de classification
- Choisir des hyperparamÃ¨tres via expÃ©rimentation

---

ğŸ“‚ _Ce projet fait partie de mon portfolio dâ€™apprentissage machine. Il illustre lâ€™utilisation de KNN pour des problÃ¨mes de classification simples avec une forte composante visuelle._

---

# ğŸ§  RÃ©seaux de Neurones (NN, MLP, CNN, Transfer Learning) avec Python

Ce projet prÃ©sente une exploration comparative de diffÃ©rents types de **rÃ©seaux de neurones profonds** appliquÃ©s Ã  la classification dâ€™images. Lâ€™Ã©tude couvre les **rÃ©seaux de neurones simples (NN)**, **les perceptrons multicouches (MLP)**, **les rÃ©seaux de neurones convolutifs (CNN)** ainsi que le **transfer learning** Ã  lâ€™aide de modÃ¨les prÃ©-entraÃ®nÃ©s.

ğŸ”— **Notebook GitHub** : [NN_MLP_CNN_Transfert_learning.ipynb](https://github.com/JWulfran/Machine-learning/blob/115f7806111e91004a1b0b3f92fd9771cf98c8bc/NN_MLP_CNN_Transfert_learning.ipynb)

---

## ğŸ¯ Objectifs

- Comprendre le fonctionnement et les diffÃ©rences entre NN, MLP et CNN
- ImplÃ©menter un pipeline de classification dâ€™images
- Utiliser des modÃ¨les prÃ©-entraÃ®nÃ©s pour amÃ©liorer la prÃ©cision (transfer learning)
- Comparer les performances de chaque modÃ¨le

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python** : NumPy, Pandas
- **TensorFlow / Keras** : pour la modÃ©lisation des rÃ©seaux de neurones
- **Matplotlib / Seaborn** : visualisation des courbes dâ€™apprentissage
- **Scikit-learn** : mÃ©triques dâ€™Ã©valuation

---

## ğŸ§ª MÃ©thodologie

1. **Chargement et prÃ©traitement des donnÃ©es**
   - Redimensionnement, normalisation, encodage
2. **ModÃ©lisation**
   - Construction de rÃ©seaux NN, MLP, CNN
   - Application de **transfer learning** avec un modÃ¨le tel que **VGG16** ou **MobileNet**
3. **EntraÃ®nement**
   - Suivi des performances sur donnÃ©es de validation
4. **Ã‰valuation**
   - Matrice de confusion, courbe de perte, prÃ©cision
5. **Comparaison des rÃ©sultats**
   - Analyse des performances en fonction de la complexitÃ© des modÃ¨les

---

## ğŸ“Š RÃ©sultats

- Les **CNN** surpassent largement les NN et MLP sur les images grÃ¢ce Ã  lâ€™extraction de caractÃ©ristiques spatiales.
- Le **transfer learning** permet une **amÃ©lioration significative de la prÃ©cision**, mÃªme avec peu de donnÃ©es.
- Visualisation des performances via **accuracy**, **loss**, et **matrices de confusion**.

---

## ğŸ§  Ce que jâ€™ai appris

- Conception et entraÃ®nement de modÃ¨les de deep learning
- Avantages du transfer learning dans les tÃ¢ches de vision par ordinateur
- Importance du prÃ©traitement pour de bonnes performances
- Analyse des rÃ©sultats pour guider le choix des architectures

---

ğŸ“‚ _Ce projet fait partie de mon portfolio data science et deep learning. Il dÃ©montre ma capacitÃ© Ã  mettre en Å“uvre des solutions dâ€™IA pour la classification dâ€™images avec rigueur et clartÃ©._
